"""Base reward interface for extensible reward design."""

from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional


@dataclass
class SolverRewardResult:
    """Structured result for solver reward computation."""

    total: float = 0.0
    correctness: float = 0.0
    context_grounding: float = 0.0
    tool_usage: float = 0.0
    details: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ChallengeRewardResult:
    """Structured result for challenge reward computation."""

    total: float = 0.0
    correctness: float = 0.0
    repetition_penalty: float = 0.0
    format_penalty: float = 0.0
    relevance: float = 0.0
    rubric_quality: float = 0.0
    details: Dict[str, Any] = field(default_factory=dict)


class BaseReward(ABC):
    """Abstract base class for dual rewards (Solver + Challenge)."""

    @abstractmethod
    def compute_solver_reward(
        self,
        answer: str,
        rubrics: List[str],
        context: str,
        metadata: Dict[str, Any],
        **kwargs,
    ) -> SolverRewardResult:
        """
        Compute reward for the Solver model based on its answer.

        Args:
            answer: Solver's generated answer.
            rubrics: List of evaluation criteria.
            context: The full context provided to the solver.
            metadata: Task metadata (task_id, context_id, context_category, sub_category).
            **kwargs: Additional context (e.g., challenge_output, messages).

        Returns:
            SolverRewardResult with breakdown of reward components.
        """
        pass

    @abstractmethod
    def compute_challenge_reward(
        self,
        solver_correctness: float,
        challenge_output: str,
        context: str,
        question: str,
        rubrics: List[str],
        metadata: Dict[str, Any],
        **kwargs,
    ) -> ChallengeRewardResult:
        """
        Compute reward for the Challenge model.

        Args:
            solver_correctness: Binary correctness (0/1) from the solver evaluation.
            challenge_output: Raw text generated by the challenge model.
            context: Original context provided to challenge model.
            question: Question generated or passed through by challenge model.
            rubrics: Rubrics generated or used by challenge model.
            metadata: Task metadata.
            **kwargs: Additional context.

        Returns:
            ChallengeRewardResult with breakdown of reward components.
        """
        pass
